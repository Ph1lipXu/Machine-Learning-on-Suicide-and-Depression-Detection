{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ph1lipXu/Machine-Learning-on-Suicide-and-Depression-Detection/blob/main/Modeling_16000.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "jx_vlHyX_UCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow nltk scikit-learn\n",
        "!pip install gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, SimpleRNN, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import gensim\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "pd.options.display.max_columns = 20\n",
        "pd.options.display.max_rows = 20\n",
        "pd.options.display.max_colwidth = 80\n",
        "np.set_printoptions(precision = 4, suppress = True)"
      ],
      "metadata": {
        "id": "wZAGxndo_YKM",
        "collapsed": true,
        "outputId": "bbe2f632-196c-4f17-db91-4219b0eddd08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrqfA4dE_QDL",
        "outputId": "e2c6f8d4-e390-439f-8ba1-29b0abd2dcfa",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-11 20:54:30--  https://raw.githubusercontent.com/Ph1lipXu/Machine-Learning-on-Suicide-and-Depression-Detection/refs/heads/main/data/cleaned_data_16000.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36085156 (34M) [text/plain]\n",
            "Saving to: ‘cleaned_data_16000.csv.2’\n",
            "\n",
            "cleaned_data_16000. 100%[===================>]  34.41M   188MB/s    in 0.2s    \n",
            "\n",
            "2025-04-11 20:54:31 (188 MB/s) - ‘cleaned_data_16000.csv.2’ saved [36085156/36085156]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Ph1lipXu/Machine-Learning-on-Suicide-and-Depression-Detection/refs/heads/main/data/cleaned_data_16000.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/cleaned_data_16000.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IWg9ccPYY68k",
        "outputId": "52f3b311-8b17-4ed8-ff69-f2ccae27f845"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                              text  \\\n",
              "0  can i get some support please...so i am not as depressed as i used to be (i ...   \n",
              "1  everything is going wrong .i have been trying not to drink, but everyone is ...   \n",
              "2                                                     i am done fighting it.*gone*   \n",
              "3  today i cut my hairmy hair has always been a thick mess of curls that went a...   \n",
              "4  i do not know what to do and i have no hopes for the future.it is kinda toug...   \n",
              "\n",
              "        class  \\\n",
              "0  depression   \n",
              "1  depression   \n",
              "2  depression   \n",
              "3  depression   \n",
              "4  depression   \n",
              "\n",
              "                                                                            tokens  \n",
              "0  ['can', 'I', 'get', 'some', 'support', 'please', 'so', 'I', 'be', 'not', 'as...  \n",
              "1  ['everything', 'be', 'go', 'wrong', 'have', 'be', 'try', 'not', 'to', 'drink...  \n",
              "2                                           ['I', 'be', 'do', 'fight', 'it', 'go']  \n",
              "3  ['today', 'I', 'cut', 'my', 'hairmy', 'hair', 'have', 'always', 'be', 'a', '...  \n",
              "4  ['I', 'do', 'not', 'know', 'what', 'to', 'do', 'and', 'I', 'have', 'no', 'ho...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28e284ad-6b55-4d0f-8b0d-f3c1fe9577cd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>can i get some support please...so i am not as depressed as i used to be (i ...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['can', 'I', 'get', 'some', 'support', 'please', 'so', 'I', 'be', 'not', 'as...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>everything is going wrong .i have been trying not to drink, but everyone is ...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['everything', 'be', 'go', 'wrong', 'have', 'be', 'try', 'not', 'to', 'drink...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i am done fighting it.*gone*</td>\n",
              "      <td>depression</td>\n",
              "      <td>['I', 'be', 'do', 'fight', 'it', 'go']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>today i cut my hairmy hair has always been a thick mess of curls that went a...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['today', 'I', 'cut', 'my', 'hairmy', 'hair', 'have', 'always', 'be', 'a', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i do not know what to do and i have no hopes for the future.it is kinda toug...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['I', 'do', 'not', 'know', 'what', 'to', 'do', 'and', 'I', 'have', 'no', 'ho...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28e284ad-6b55-4d0f-8b0d-f3c1fe9577cd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28e284ad-6b55-4d0f-8b0d-f3c1fe9577cd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28e284ad-6b55-4d0f-8b0d-f3c1fe9577cd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8439bd8f-0425-4ba2-9c30-d26a09229d95\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8439bd8f-0425-4ba2-9c30-d26a09229d95')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8439bd8f-0425-4ba2-9c30-d26a09229d95 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 16000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12918,\n        \"samples\": [\n          \"i cannot go through with iti have made the decision 4 ti ames, yet every ti ame i seem to back out last minute. i was so sure i would go through with it this ti ame, too. i quit my job, broke up with boyfriend, deleted most of my social media accounts, i was ready to just end it all. yet for some reason i still cannot work up the courage. currently parked off the road next to a bridge because i am scared and do not know what to do.\",\n          \"anyone wanna get married ? bc you can only have sex after marriage  flushed_face \",\n          \"this saturdaythat would be a good day for it. ive finally escaped peoples birthdays, so i neednt worry about that. i just need to get things settled by then.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"SuicideWatch\",\n          \"noise\",\n          \"depression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12908,\n        \"samples\": [\n          \"['at', 'what', 'ti', 'ame', 'do', 'you', 'usually', 'workout', 'personally', 'I', 'just', 'try', 'to', 'be', 'randomly', 'active', 'throughout', 'the', 'day', 'cause', 'I', 'do', 'not', 'know', 'how', 'to', 'focus', 'myself', 'into', 'a', 'workout', 'most', 'of', 'the', 'ti', 'ame', 'which', 'be', 'really', 'I', 'amportant', 'to', 'I', 'because', 'constantly', 'force', 'yourself', 'to', 'do', 'something', 'take', 'a', 'huge', 'toll', 'on', 'your', 'mental', 'health', 'I', 'have', 'try', 'to', 'get', 'into', 'moright', 'nowe', 'workout', 'but', 'I', 'be', 'never', 'feel', 'it', 'or', 'I', 'sleep', 'in', 'usually', 'I', 'start', 'around', 'so', 'I', 'can', 'sleep', 'like', 'the', 'dead', 'even', 'thoughugh', 'they', 'say', 'you', 'should', 'not', 'do', 'that', 'but', 'I', 'be', 'type', 'this', 'at', 'am', 'because', 'I', 'mess', 'up', 'my', 'sleep', 'schedule', 'in', 'the', 'past', 'week', 'I', 'be', 'wonder', 'if', 'I', 'should', 'use', 'this', 'opportunity', 'to', 'try', 'and', 'start', 'a', 'moright', 'nowing', 'routine', 'again']\",\n          \"['anyone', 'wan', 'na', 'make', 'a', 'discord', 'server', 'together', 'it', 'can', 'be', 'about', 'whatever', 'you', 'want', 'I', 'be', 'just', 'that', 'bored', 'really']\",\n          \"['I', 'make', 'this', 'survey', 'on', 'social', 'comparison', 'and', 'in', 'psychology', 'hey', 'I', 'be', 'do', 'an', 'anonymous', 'survey', 'about', 'social', 'comparison', 'and', 'as', 'a', 'task', 'in', 'psychology', 'class', 'I', 'would', 'greatly', 'appreciate', 'if', 'anybody', 'would', 'like', 'to', 'participate', 'thank', 'in', 'advance', 'link', 'https']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHw9aZRJ7aBI"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['suicide_class'] = df['class'].apply(lambda x: 'suicide' if x == 'SuicideWatch' else 'nonsuicide')\n",
        "df['depression_class'] = df['class'].apply(lambda x: 'depression' if x == 'depression' else 'nondepression')\n",
        "df['teenager_class'] = df['class'].apply(lambda x: 'teenager' if x == 'teenagers' else 'nonteenager')"
      ],
      "metadata": {
        "id": "RvGbnNesc6-N"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "mnf7KB_cc8Mu",
        "outputId": "f5966019-0254-4bb7-e52e-ebdddd8bc6f1"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                              text  \\\n",
              "0  can i get some support please...so i am not as depressed as i used to be (i ...   \n",
              "1  everything is going wrong .i have been trying not to drink, but everyone is ...   \n",
              "2                                                     i am done fighting it.*gone*   \n",
              "3  today i cut my hairmy hair has always been a thick mess of curls that went a...   \n",
              "4  i do not know what to do and i have no hopes for the future.it is kinda toug...   \n",
              "5  tired of life, tired of living. do not know what to do hey guys, \\n\\ni am 16...   \n",
              "6  what is one concrete thing that has helped you in your battle against depres...   \n",
              "7  does mental health go hand in hand with the physical health?when i feel at m...   \n",
              "8  the thing that hurts the most is knowing that i have been through worse.when...   \n",
              "9  need someone to talk toi am a guy in high school and i just need to talk to ...   \n",
              "\n",
              "        class  \\\n",
              "0  depression   \n",
              "1  depression   \n",
              "2  depression   \n",
              "3  depression   \n",
              "4  depression   \n",
              "5  depression   \n",
              "6  depression   \n",
              "7  depression   \n",
              "8  depression   \n",
              "9  depression   \n",
              "\n",
              "                                                                            tokens  \\\n",
              "0  ['can', 'I', 'get', 'some', 'support', 'please', 'so', 'I', 'be', 'not', 'as...   \n",
              "1  ['everything', 'be', 'go', 'wrong', 'have', 'be', 'try', 'not', 'to', 'drink...   \n",
              "2                                           ['I', 'be', 'do', 'fight', 'it', 'go']   \n",
              "3  ['today', 'I', 'cut', 'my', 'hairmy', 'hair', 'have', 'always', 'be', 'a', '...   \n",
              "4  ['I', 'do', 'not', 'know', 'what', 'to', 'do', 'and', 'I', 'have', 'no', 'ho...   \n",
              "5  ['tired', 'of', 'life', 'tired', 'of', 'live', 'do', 'not', 'know', 'what', ...   \n",
              "6  ['what', 'be', 'one', 'concrete', 'thing', 'that', 'have', 'help', 'you', 'i...   \n",
              "7  ['do', 'mental', 'health', 'go', 'hand', 'in', 'hand', 'with', 'the', 'physi...   \n",
              "8  ['the', 'thing', 'that', 'hurt', 'the', 'most', 'be', 'know', 'that', 'I', '...   \n",
              "9  ['need', 'someone', 'to', 'talk', 'toi', 'be', 'a', 'guy', 'in', 'high', 'sc...   \n",
              "\n",
              "  suicide_class depression_class teenager_class  \n",
              "0    nonsuicide       depression    nonteenager  \n",
              "1    nonsuicide       depression    nonteenager  \n",
              "2    nonsuicide       depression    nonteenager  \n",
              "3    nonsuicide       depression    nonteenager  \n",
              "4    nonsuicide       depression    nonteenager  \n",
              "5    nonsuicide       depression    nonteenager  \n",
              "6    nonsuicide       depression    nonteenager  \n",
              "7    nonsuicide       depression    nonteenager  \n",
              "8    nonsuicide       depression    nonteenager  \n",
              "9    nonsuicide       depression    nonteenager  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0043dfd9-cbd4-48ee-8c2f-c384488be568\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "      <th>tokens</th>\n",
              "      <th>suicide_class</th>\n",
              "      <th>depression_class</th>\n",
              "      <th>teenager_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>can i get some support please...so i am not as depressed as i used to be (i ...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['can', 'I', 'get', 'some', 'support', 'please', 'so', 'I', 'be', 'not', 'as...</td>\n",
              "      <td>nonsuicide</td>\n",
              "      <td>depression</td>\n",
              "      <td>nonteenager</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>everything is going wrong .i have been trying not to drink, but everyone is ...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['everything', 'be', 'go', 'wrong', 'have', 'be', 'try', 'not', 'to', 'drink...</td>\n",
              "      <td>nonsuicide</td>\n",
              "      <td>depression</td>\n",
              "      <td>nonteenager</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i am done fighting it.*gone*</td>\n",
              "      <td>depression</td>\n",
              "      <td>['I', 'be', 'do', 'fight', 'it', 'go']</td>\n",
              "      <td>nonsuicide</td>\n",
              "      <td>depression</td>\n",
              "      <td>nonteenager</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>today i cut my hairmy hair has always been a thick mess of curls that went a...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['today', 'I', 'cut', 'my', 'hairmy', 'hair', 'have', 'always', 'be', 'a', '...</td>\n",
              "      <td>nonsuicide</td>\n",
              "      <td>depression</td>\n",
              "      <td>nonteenager</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i do not know what to do and i have no hopes for the future.it is kinda toug...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['I', 'do', 'not', 'know', 'what', 'to', 'do', 'and', 'I', 'have', 'no', 'ho...</td>\n",
              "      <td>nonsuicide</td>\n",
              "      <td>depression</td>\n",
              "      <td>nonteenager</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>tired of life, tired of living. do not know what to do hey guys, \\n\\ni am 16...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['tired', 'of', 'life', 'tired', 'of', 'live', 'do', 'not', 'know', 'what', ...</td>\n",
              "      <td>nonsuicide</td>\n",
              "      <td>depression</td>\n",
              "      <td>nonteenager</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>what is one concrete thing that has helped you in your battle against depres...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['what', 'be', 'one', 'concrete', 'thing', 'that', 'have', 'help', 'you', 'i...</td>\n",
              "      <td>nonsuicide</td>\n",
              "      <td>depression</td>\n",
              "      <td>nonteenager</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>does mental health go hand in hand with the physical health?when i feel at m...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['do', 'mental', 'health', 'go', 'hand', 'in', 'hand', 'with', 'the', 'physi...</td>\n",
              "      <td>nonsuicide</td>\n",
              "      <td>depression</td>\n",
              "      <td>nonteenager</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>the thing that hurts the most is knowing that i have been through worse.when...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['the', 'thing', 'that', 'hurt', 'the', 'most', 'be', 'know', 'that', 'I', '...</td>\n",
              "      <td>nonsuicide</td>\n",
              "      <td>depression</td>\n",
              "      <td>nonteenager</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>need someone to talk toi am a guy in high school and i just need to talk to ...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['need', 'someone', 'to', 'talk', 'toi', 'be', 'a', 'guy', 'in', 'high', 'sc...</td>\n",
              "      <td>nonsuicide</td>\n",
              "      <td>depression</td>\n",
              "      <td>nonteenager</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0043dfd9-cbd4-48ee-8c2f-c384488be568')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0043dfd9-cbd4-48ee-8c2f-c384488be568 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0043dfd9-cbd4-48ee-8c2f-c384488be568');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6d1f2f4c-3dcf-4644-ba23-439ac654bf43\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d1f2f4c-3dcf-4644-ba23-439ac654bf43')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6d1f2f4c-3dcf-4644-ba23-439ac654bf43 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 16000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12918,\n        \"samples\": [\n          \"i cannot go through with iti have made the decision 4 ti ames, yet every ti ame i seem to back out last minute. i was so sure i would go through with it this ti ame, too. i quit my job, broke up with boyfriend, deleted most of my social media accounts, i was ready to just end it all. yet for some reason i still cannot work up the courage. currently parked off the road next to a bridge because i am scared and do not know what to do.\",\n          \"anyone wanna get married ? bc you can only have sex after marriage  flushed_face \",\n          \"this saturdaythat would be a good day for it. ive finally escaped peoples birthdays, so i neednt worry about that. i just need to get things settled by then.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"SuicideWatch\",\n          \"noise\",\n          \"depression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12908,\n        \"samples\": [\n          \"['at', 'what', 'ti', 'ame', 'do', 'you', 'usually', 'workout', 'personally', 'I', 'just', 'try', 'to', 'be', 'randomly', 'active', 'throughout', 'the', 'day', 'cause', 'I', 'do', 'not', 'know', 'how', 'to', 'focus', 'myself', 'into', 'a', 'workout', 'most', 'of', 'the', 'ti', 'ame', 'which', 'be', 'really', 'I', 'amportant', 'to', 'I', 'because', 'constantly', 'force', 'yourself', 'to', 'do', 'something', 'take', 'a', 'huge', 'toll', 'on', 'your', 'mental', 'health', 'I', 'have', 'try', 'to', 'get', 'into', 'moright', 'nowe', 'workout', 'but', 'I', 'be', 'never', 'feel', 'it', 'or', 'I', 'sleep', 'in', 'usually', 'I', 'start', 'around', 'so', 'I', 'can', 'sleep', 'like', 'the', 'dead', 'even', 'thoughugh', 'they', 'say', 'you', 'should', 'not', 'do', 'that', 'but', 'I', 'be', 'type', 'this', 'at', 'am', 'because', 'I', 'mess', 'up', 'my', 'sleep', 'schedule', 'in', 'the', 'past', 'week', 'I', 'be', 'wonder', 'if', 'I', 'should', 'use', 'this', 'opportunity', 'to', 'try', 'and', 'start', 'a', 'moright', 'nowing', 'routine', 'again']\",\n          \"['anyone', 'wan', 'na', 'make', 'a', 'discord', 'server', 'together', 'it', 'can', 'be', 'about', 'whatever', 'you', 'want', 'I', 'be', 'just', 'that', 'bored', 'really']\",\n          \"['I', 'make', 'this', 'survey', 'on', 'social', 'comparison', 'and', 'in', 'psychology', 'hey', 'I', 'be', 'do', 'an', 'anonymous', 'survey', 'about', 'social', 'comparison', 'and', 'as', 'a', 'task', 'in', 'psychology', 'class', 'I', 'would', 'greatly', 'appreciate', 'if', 'anybody', 'would', 'like', 'to', 'participate', 'thank', 'in', 'advance', 'link', 'https']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"suicide_class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"suicide\",\n          \"nonsuicide\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"depression_class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"nondepression\",\n          \"depression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"teenager_class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"teenager\",\n          \"nonteenager\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKZo9e-pR9UD"
      },
      "source": [
        "## Suicide / Non-Suicide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "jNebm64XTRpo"
      },
      "outputs": [],
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"label\"] = label_encoder.fit_transform(df[\"suicide_class\"])\n",
        "num_classes = len(label_encoder.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs-OLe6209Yo",
        "outputId": "c2325e6e-023b-4dde-e9f0-ed4aec14f0ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data:  12000\n",
            "Testing data:  4000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Instead of random train test split, stratify by class\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df[\"tokens\"], df[\"label\"], random_state=64, stratify=df['label']\n",
        ")\n",
        "print('Training data: ',len(train_texts))\n",
        "print('Testing data: ',len(test_texts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "jCo8KR7TsLpe"
      },
      "outputs": [],
      "source": [
        "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQe7527viLtq",
        "outputId": "f5c8f23d-cb7e-4560-9bbb-e5d4315f645b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1435     ['anyone', 'else', 'feel', 'like', 'this', 'I', 'have', 'be', 'cope', 'with'...\n",
            "1368     ['lose', 'my', 'sense', 'of', 'realityit', 'be', 'another', 'one', 'of', 'th...\n",
            "5863                                          ['good', 'way', 'to', 'commit', 'suicide']\n",
            "8929     ['I', 'be', 'bakk', 'you', 'lousy', 'son', 'of', 'bitch', 'thoughught', 'I',...\n",
            "15448    ['firstly', 'what', 'be', 'your', 'thoughught', 'on', 'the', 'titular', 'cha...\n",
            "11663    ['just', 'realize', 'how', 'close', 'my', 'teenage', 'year', 'be', 'to', 'fi...\n",
            "3897     ['just', 'a', 'thoughught', 'that', 'enter', 'my', 'mind', 'lie', 'in', 'bed...\n",
            "4635     ['why', 'when', 'I', 'die', 'the', 'world', 'will', 'not', 'stop', 'spin', '...\n",
            "14158    ['we', 'just', 'have', 'our', 'concrete', 'foundation', 'reinforce', 'so', '...\n",
            "13454    ['my', 'wife', 'be', 'italian', 'and', 'my', 'do', 'not', 'speak', 'very', '...\n",
            "Name: tokens, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(train_texts.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqhtvxmjmBQT"
      },
      "source": [
        "### Vectorization/Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "s0da8ceRTxxe"
      },
      "outputs": [],
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Convert texts to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
        "\n",
        "# Padding sequences to have the same length\n",
        "max_len = 200  # Max length for padding\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Vocabulary size\n",
        "vocab_size = len(word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bi3JxsDHTvF8",
        "outputId": "b005562e-8fdc-4830-b0ff-4dd0a5bed823",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        }
      ],
      "source": [
        "word2vec_model = gensim.models.Word2Vec(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "fasttext_model = gensim.models.FastText(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "embedding_matrix_w2v = np.zeros((vocab_size, 100))\n",
        "embedding_matrix_ft = np.zeros((vocab_size, 100))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if word in word2vec_model.wv:\n",
        "        embedding_matrix_w2v[i] = word2vec_model.wv[word]\n",
        "    if word in fasttext_model.wv:\n",
        "        embedding_matrix_ft[i] = fasttext_model.wv[word]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.metrics import f1_score\n",
        "class F1ScoreCallback(Callback):\n",
        "    def __init__(self, validation_data):\n",
        "        self.validation_data = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_data, val_labels = self.validation_data\n",
        "        val_preds = self.model.predict(val_data)\n",
        "        val_preds = np.argmax(val_preds, axis=1)  # Convert probabilities to class labels\n",
        "        val_labels = np.argmax(val_labels, axis=1)  # Convert one-hot labels to class labels\n",
        "\n",
        "        f1 = f1_score(val_labels, val_preds, average='weighted')  # Change to 'macro' if needed\n",
        "        print(f\" - val_f1: {f1:.4f}\")\n",
        "        logs[\"val_f1\"] = f1  # Store it in logs if needed"
      ],
      "metadata": {
        "id": "HXNQxOpT3kLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cjJ-leXT_Ci"
      },
      "outputs": [],
      "source": [
        "def build_cnn_model(vocab_size, embedding_matrix, num_classes):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_len, trainable=False),\n",
        "        Conv1D(128, 5, activation='relu'),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_rnn_model(vocab_size, embedding_matrix, num_classes):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_len, trainable=False),\n",
        "        LSTM(128, return_sequences=False),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_bilstm_model(vocab_size, embedding_matrix, num_classes):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_len, trainable=False),\n",
        "        Bidirectional(LSTM(128)),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate(model, train_padded, train_labels, test_padded, test_labels, epochs=10, batch_size=32):\n",
        "    f1_callback = F1ScoreCallback(validation_data=(test_padded, test_labels))\n",
        "\n",
        "    model.fit(train_padded, train_labels,\n",
        "              epochs=epochs, batch_size=batch_size,\n",
        "              validation_data=(test_padded, test_labels),\n",
        "              callbacks=[f1_callback])\n",
        "\n",
        "    loss, acc = model.evaluate(test_padded, test_labels)\n",
        "    print(f\"Test Accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2P6arsDUH9X"
      },
      "outputs": [],
      "source": [
        "print(\"Training Bi-LSTM with Word2Vec Embeddings...\")\n",
        "bilstm_model = build_bilstm_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(bilstm_model, train_padded, train_labels, test_padded, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jS-KZPWW4rS"
      },
      "outputs": [],
      "source": [
        "print(\"Training Bi-LSTM with FastText Embeddings...\")\n",
        "bilstm_model = build_bilstm_model(vocab_size, embedding_matrix_ft, num_classes)\n",
        "train_and_evaluate(bilstm_model, train_padded, train_labels, test_padded, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fi8P_Yw_UdH3"
      },
      "outputs": [],
      "source": [
        "print(\"Training CNN with Word2Vec Embeddings...\")\n",
        "cnn_model = build_cnn_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(cnn_model, train_padded, train_labels, test_padded, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdp_PZ8vXCOA"
      },
      "outputs": [],
      "source": [
        "print(\"Training CNN with FastText Embeddings...\")\n",
        "cnn_model = build_cnn_model(vocab_size, embedding_matrix_ft, num_classes)\n",
        "train_and_evaluate(cnn_model, train_padded, train_labels, test_padded, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hf3hFIFYAOZ"
      },
      "source": [
        "### Tokenized\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHSomU-CYBiO"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "df[\"label\"] = label_encoder.fit_transform(df[\"suicide_class\"])\n",
        "num_classes = len(label_encoder.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvaumW1YYFn6"
      },
      "outputs": [],
      "source": [
        "train_texts, test_texts, train_labels, test_labels = train_test_split(df[\"tokens\"], df[\"label\"], test_size=0.2, random_state=64)\n",
        "\n",
        "# Train Word2Vec and FastText models\n",
        "word2vec_model = gensim.models.Word2Vec(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "fasttext_model = gensim.models.FastText(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_texts.apply(' '.join))  # Join tokens back to text for the tokenizer\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "# Create embedding matrices\n",
        "embedding_matrix_w2v = np.zeros((vocab_size, 100))\n",
        "embedding_matrix_ft = np.zeros((vocab_size, 100))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if word in word2vec_model.wv:\n",
        "        embedding_matrix_w2v[i] = word2vec_model.wv[word]\n",
        "    if word in fasttext_model.wv:\n",
        "        embedding_matrix_ft[i] = fasttext_model.wv[word]\n",
        "\n",
        "max_len = 100  # Max length for padding\n",
        "\n",
        "# Convert texts to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts.apply(' '.join))  # Join tokens for sequences\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts.apply(' '.join))\n",
        "\n",
        "# Padding sequences\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Convert labels to categorical\n",
        "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes=num_classes)\n",
        "\n",
        "# Train Bi-LSTM with Word2Vec embeddings\n",
        "print(\"Training Bi-LSTM with Word2Vec Embeddings...\")\n",
        "bilstm_model = build_bilstm_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(bilstm_model, train_padded, train_labels, test_padded, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, test_texts, train_labels, test_labels = train_test_split(df[\"tokens\"], df[\"label\"], test_size=0.2, random_state=64)\n",
        "\n",
        "# Train Word2Vec and FastText models\n",
        "word2vec_model = gensim.models.Word2Vec(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "fasttext_model = gensim.models.FastText(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_texts.apply(' '.join))  # Join tokens back to text for the tokenizer\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "# Create embedding matrices\n",
        "embedding_matrix_w2v = np.zeros((vocab_size, 100))\n",
        "embedding_matrix_ft = np.zeros((vocab_size, 100))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if word in word2vec_model.wv:\n",
        "        embedding_matrix_w2v[i] = word2vec_model.wv[word]\n",
        "    if word in fasttext_model.wv:\n",
        "        embedding_matrix_ft[i] = fasttext_model.wv[word]\n",
        "\n",
        "max_len = 100  # Max length for padding\n",
        "\n",
        "# Convert texts to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts.apply(' '.join))  # Join tokens for sequences\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts.apply(' '.join))\n",
        "\n",
        "# Padding sequences\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Convert labels to categorical\n",
        "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes=num_classes)\n",
        "\n",
        "# Train Bi-LSTM with Word2Vec embeddings\n",
        "print(\"Training RNN with Word2Vec Embeddings...\")\n",
        "bilstm_model = build_rnn_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(bilstm_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "id": "N54reRRQePJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Depression / Non-Depression"
      ],
      "metadata": {
        "id": "0ZYEKPCQfRSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df['depression_class'] = depression_df['class'].apply(lambda x: 'depression' if x == 'depression' else 'nondepression')"
      ],
      "metadata": {
        "id": "T5DD-VDDfbnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"label\"] = label_encoder.fit_transform(df[\"depression_class\"])\n",
        "num_classes = len(label_encoder.classes_)"
      ],
      "metadata": {
        "id": "5w1LbU5wf_5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Instead of random train test split, stratify by class\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df[\"tokens\"], df[\"label\"], random_state=64, stratify=df['label']\n",
        ")"
      ],
      "metadata": {
        "id": "Xj4PsEbphVsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes=num_classes)"
      ],
      "metadata": {
        "id": "JqB-0wFEhY8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorization/Embedding"
      ],
      "metadata": {
        "id": "MZ9L_UFphfMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Convert texts to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
        "\n",
        "# Padding sequences to have the same length\n",
        "max_len = 200  # Max length for padding\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Vocabulary size\n",
        "vocab_size = len(word_index) + 1"
      ],
      "metadata": {
        "id": "dVjANGhBhiyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model = gensim.models.Word2Vec(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "fasttext_model = gensim.models.FastText(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "embedding_matrix_w2v = np.zeros((vocab_size, 100))\n",
        "embedding_matrix_ft = np.zeros((vocab_size, 100))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if word in word2vec_model.wv:\n",
        "        embedding_matrix_w2v[i] = word2vec_model.wv[word]\n",
        "    if word in fasttext_model.wv:\n",
        "        embedding_matrix_ft[i] = fasttext_model.wv[word]"
      ],
      "metadata": {
        "id": "P8Ia4s8thpKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Bi-LSTM with Word2Vec Embeddings...\")\n",
        "bilstm_model = build_bilstm_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(bilstm_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "id": "gVe6qK6sik3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Bi-LSTM with FastText Embeddings...\")\n",
        "bilstm_model = build_bilstm_model(vocab_size, embedding_matrix_ft, num_classes)\n",
        "train_and_evaluate(bilstm_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "id": "fTah2KHafIt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training CNN with Word2Vec Embeddings...\")\n",
        "cnn_model = build_cnn_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(cnn_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "id": "nRK9k2sEfMRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training CNN with FastText Embeddings...\")\n",
        "cnn_model = build_cnn_model(vocab_size, embedding_matrix_ft, num_classes)\n",
        "train_and_evaluate(cnn_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "id": "iVYT0JdefMn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenized"
      ],
      "metadata": {
        "id": "x9YMbGOJinw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "df[\"label\"] = label_encoder.fit_transform(df[\"depression_class\"])\n",
        "num_classes = len(label_encoder.classes_)"
      ],
      "metadata": {
        "id": "5UKZ21A4iuFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, test_texts, train_labels, test_labels = train_test_split(df[\"tokens\"], df[\"label\"], test_size=0.2, random_state=64)\n",
        "\n",
        "# Train Word2Vec and FastText models\n",
        "word2vec_model = gensim.models.Word2Vec(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "fasttext_model = gensim.models.FastText(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_texts.apply(' '.join))  # Join tokens back to text for the tokenizer\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "# Create embedding matrices\n",
        "embedding_matrix_w2v = np.zeros((vocab_size, 100))\n",
        "embedding_matrix_ft = np.zeros((vocab_size, 100))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if word in word2vec_model.wv:\n",
        "        embedding_matrix_w2v[i] = word2vec_model.wv[word]\n",
        "    if word in fasttext_model.wv:\n",
        "        embedding_matrix_ft[i] = fasttext_model.wv[word]\n",
        "\n",
        "max_len = 100  # Max length for padding\n",
        "\n",
        "# Convert texts to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts.apply(' '.join))  # Join tokens for sequences\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts.apply(' '.join))\n",
        "\n",
        "# Padding sequences\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Convert labels to categorical\n",
        "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes=num_classes)\n",
        "\n",
        "# Train Bi-LSTM with Word2Vec embeddings\n",
        "print(\"Training Bi-LSTM with Word2Vec Embeddings...\")\n",
        "bilstm_model = build_bilstm_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(bilstm_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "id": "H0gEzTcYixt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, test_texts, train_labels, test_labels = train_test_split(df[\"tokens\"], df[\"label\"], test_size=0.2, random_state=64)\n",
        "\n",
        "# Train Word2Vec and FastText models\n",
        "word2vec_model = gensim.models.Word2Vec(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "fasttext_model = gensim.models.FastText(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_texts.apply(' '.join))  # Join tokens back to text for the tokenizer\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "# Create embedding matrices\n",
        "embedding_matrix_w2v = np.zeros((vocab_size, 100))\n",
        "embedding_matrix_ft = np.zeros((vocab_size, 100))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if word in word2vec_model.wv:\n",
        "        embedding_matrix_w2v[i] = word2vec_model.wv[word]\n",
        "    if word in fasttext_model.wv:\n",
        "        embedding_matrix_ft[i] = fasttext_model.wv[word]\n",
        "\n",
        "max_len = 100  # Max length for padding\n",
        "\n",
        "# Convert texts to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts.apply(' '.join))  # Join tokens for sequences\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts.apply(' '.join))\n",
        "\n",
        "# Padding sequences\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Convert labels to categorical\n",
        "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes=num_classes)\n",
        "\n",
        "# Train Bi-LSTM with Word2Vec embeddings\n",
        "print(\"Training RNN with Word2Vec Embeddings...\")\n",
        "bilstm_model = build_rnn_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(bilstm_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "id": "E1piXu-4frXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teenager / Non-Teenager\n"
      ],
      "metadata": {
        "id": "BowN0hrtgd84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['teenager_class'] = df['class'].apply(lambda x: 'teenager' if x == 'teenagers' else 'nonteenager')"
      ],
      "metadata": {
        "id": "5JBG2bf-gjLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"label\"] = label_encoder.fit_transform(df[\"teenager_class\"])\n",
        "num_classes = len(label_encoder.classes_)"
      ],
      "metadata": {
        "id": "tb7dCmqJg3sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorization/Embedding"
      ],
      "metadata": {
        "id": "L7opjK5IjMnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Convert texts to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
        "\n",
        "# Padding sequences to have the same length\n",
        "max_len = 200  # Max length for padding\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Vocabulary size\n",
        "vocab_size = len(word_index) + 1"
      ],
      "metadata": {
        "id": "RLObioXzjP2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model = gensim.models.Word2Vec(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "fasttext_model = gensim.models.FastText(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "embedding_matrix_w2v = np.zeros((vocab_size, 100))\n",
        "embedding_matrix_ft = np.zeros((vocab_size, 100))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if word in word2vec_model.wv:\n",
        "        embedding_matrix_w2v[i] = word2vec_model.wv[word]\n",
        "    if word in fasttext_model.wv:\n",
        "        embedding_matrix_ft[i] = fasttext_model.wv[word]"
      ],
      "metadata": {
        "id": "dN11WPKMjkgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Bi-LSTM with Word2Vec Embeddings...\")\n",
        "bilstm_model = build_bilstm_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(bilstm_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "id": "kx0b_T0XjmV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Bi-LSTM with FastText Embeddings...\")\n",
        "bilstm_model = build_bilstm_model(vocab_size, embedding_matrix_ft, num_classes)\n",
        "train_and_evaluate(bilstm_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "id": "RDGUu-XJfDiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training CNN with Word2Vec Embeddings...\")\n",
        "cnn_model = build_cnn_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(cnn_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "id": "C5KydmbcelRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training CNN with FastText Embeddings...\")\n",
        "cnn_model = build_cnn_model(vocab_size, embedding_matrix_ft, num_classes)\n",
        "train_and_evaluate(cnn_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "id": "j2biIiiweqaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training RNN with Word2Vec Embeddings...\")\n",
        "rnn_model = build_rnn_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(rnn_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "id": "qt5pGy19s220"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenized"
      ],
      "metadata": {
        "id": "jG0Ks3MLjn-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "df[\"label\"] = label_encoder.fit_transform(df[\"teenager_class\"])\n",
        "num_classes = len(label_encoder.classes_)"
      ],
      "metadata": {
        "id": "rDc3vpCejswN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, test_texts, train_labels, test_labels = train_test_split(df[\"tokens\"], df[\"label\"], test_size=0.2, random_state=64)\n",
        "\n",
        "# Train Word2Vec and FastText models\n",
        "word2vec_model = gensim.models.Word2Vec(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "fasttext_model = gensim.models.FastText(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_texts.apply(' '.join))  # Join tokens back to text for the tokenizer\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "# Create embedding matrices\n",
        "embedding_matrix_w2v = np.zeros((vocab_size, 100))\n",
        "embedding_matrix_ft = np.zeros((vocab_size, 100))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if word in word2vec_model.wv:\n",
        "        embedding_matrix_w2v[i] = word2vec_model.wv[word]\n",
        "    if word in fasttext_model.wv:\n",
        "        embedding_matrix_ft[i] = fasttext_model.wv[word]\n",
        "\n",
        "max_len = 100  # Max length for padding\n",
        "\n",
        "# Convert texts to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts.apply(' '.join))  # Join tokens for sequences\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts.apply(' '.join))\n",
        "\n",
        "# Padding sequences\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Convert labels to categorical\n",
        "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes=num_classes)\n",
        "\n",
        "# Train Bi-LSTM with Word2Vec embeddings\n",
        "print(\"Training Bi-LSTM with Word2Vec Embeddings...\")\n",
        "bilstm_model = build_bilstm_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(bilstm_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "id": "tFxv_y6ajtND"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}